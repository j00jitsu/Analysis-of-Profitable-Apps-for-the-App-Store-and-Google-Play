{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Analysis of Profitable Apps for the App Store and Google Play\n",
    "\n",
    "As of 2018, there were about 2 million iOS apps available in the App Store, and about 2.1 million Android apps in the Google Play store. This app analysis is intended to find the most profitable types of apps to develop in terms of ad revenue, as the apps themselves will be free to download. Naturally, this means that we must find the kind of apps which are most installed, since more users means more people seeing and potentially engaging with the ads. Therefore, the goal is to help our hypothetical developers understand what kinds of apps are most likely to attract the most users on both Android and iOS.\n",
    "\n",
    "We will accomplish these goals with a few fairly straightforward steps:\n",
    "\n",
    "1. Open data for the App Store and Google Play apps, and create lists to more easily process the data\n",
    "2. Clean the data by removing any incorrect, duplicate, or irrelevant apps (non-free, non-English, incorrect data)\n",
    "3. Categorize and sort the apps so we can make informed statements about which ones users prefer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data exploration and sorting\n",
    "\n",
    "Collecting data for over 4 million apps would not only be very time-consuming, it would also be expensive. Realistically, it would not even be necessary, as a smaller sample should be suitable to give us the information we need. Our data sets for the Android and iOS app stores will include about 10,000 and 7,000 apps, respectively.\n",
    "\n",
    "Opening and exploring the data sets is the logical first step. We'll use a function to allow for repeated printing of rows in a readable way."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_columns=False):\n",
    "    data_slice = dataset[start:end]\n",
    "    for row in data_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "\n",
    "    if rows_columns:\n",
    "        print(f'Number of rows: {len(dataset)}')\n",
    "        print(f'Number of columns: {len(dataset[0])}')"
   ]
  },
  {
   "source": [
    "The `explore_data()` function takes four parameters: dataset, which is expected as a list of lists; start and end, which should be integers and represent the starting/ending indices of a slice of the dataset; rows_columns, expected to be a boolean with False set as default.\n",
    "\n",
    "The function opens and slices the data. It then loops through the slice, and for each iteration prints a row and a blank line.\n",
    "\n",
    "Let's open the two app data sets and create lists from them. We'll also save each header row into its own variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "### The Google Play data set ###\n",
    "opened_file = open('googleplaystore.csv')\n",
    "read_file = reader(opened_file)\n",
    "android = list(read_file)\n",
    "android_header = android[0]\n",
    "android = android[1:]\n",
    "\n",
    "### The App Store data set ###\n",
    "opened_file = open('AppleStore.csv')\n",
    "read_file = reader(opened_file)\n",
    "ios = list(read_file)\n",
    "ios_header = ios[0]\n",
    "ios = ios[1:]"
   ]
  },
  {
   "source": [
    "Simple enough! Next, we'll use our explore_data() function to examine the first few rows of the Google data file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;App&#39;, &#39;Category&#39;, &#39;Rating&#39;, &#39;Reviews&#39;, &#39;Size&#39;, &#39;Installs&#39;, &#39;Type&#39;, &#39;Price&#39;, &#39;Content Rating&#39;, &#39;Genres&#39;, &#39;Last Updated&#39;, &#39;Current Ver&#39;, &#39;Android Ver&#39;]\n\n\n[&#39;Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook&#39;, &#39;ART_AND_DESIGN&#39;, &#39;4.1&#39;, &#39;159&#39;, &#39;19M&#39;, &#39;10,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Everyone&#39;, &#39;Art &amp; Design&#39;, &#39;January 7, 2018&#39;, &#39;1.0.0&#39;, &#39;4.0.3 and up&#39;]\n\n\n[&#39;Coloring book moana&#39;, &#39;ART_AND_DESIGN&#39;, &#39;3.9&#39;, &#39;967&#39;, &#39;14M&#39;, &#39;500,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Everyone&#39;, &#39;Art &amp; Design;Pretend Play&#39;, &#39;January 15, 2018&#39;, &#39;2.0.0&#39;, &#39;4.0.3 and up&#39;]\n\n\n[&#39;U Launcher Lite â€“ FREE Live Cool Themes, Hide Apps&#39;, &#39;ART_AND_DESIGN&#39;, &#39;4.7&#39;, &#39;87510&#39;, &#39;8.7M&#39;, &#39;5,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Everyone&#39;, &#39;Art &amp; Design&#39;, &#39;August 1, 2018&#39;, &#39;1.2.4&#39;, &#39;4.0.3 and up&#39;]\n\n\n[&#39;Sketch - Draw &amp; Paint&#39;, &#39;ART_AND_DESIGN&#39;, &#39;4.5&#39;, &#39;215644&#39;, &#39;25M&#39;, &#39;50,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Teen&#39;, &#39;Art &amp; Design&#39;, &#39;June 8, 2018&#39;, &#39;Varies with device&#39;, &#39;4.2 and up&#39;]\n\n\nNumber of rows: 10841\nNumber of columns: 13\n"
    }
   ],
   "source": [
    "print(android_header)\n",
    "print('\\n')\n",
    "explore_data(android, 0, 4, rows_columns=True)"
   ]
  },
  {
   "source": [
    "There are 10,841 apps, sorted into 13 columns. Many of the column headings seem like they will be useful to our analysis. The most relevant for now are probably 'App', 'Category', 'Rating', 'Installs', 'Type', 'Price', and 'Genres'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now let's do the same for the iOS store data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;id&#39;, &#39;track_name&#39;, &#39;size_bytes&#39;, &#39;currency&#39;, &#39;price&#39;, &#39;rating_count_tot&#39;, &#39;rating_count_ver&#39;, &#39;user_rating&#39;, &#39;user_rating_ver&#39;, &#39;ver&#39;, &#39;cont_rating&#39;, &#39;prime_genre&#39;, &#39;sup_devices.num&#39;, &#39;ipadSc_urls.num&#39;, &#39;lang.num&#39;, &#39;vpp_lic&#39;]\n\n\n[&#39;284882215&#39;, &#39;Facebook&#39;, &#39;389879808&#39;, &#39;USD&#39;, &#39;0.0&#39;, &#39;2974676&#39;, &#39;212&#39;, &#39;3.5&#39;, &#39;3.5&#39;, &#39;95.0&#39;, &#39;4+&#39;, &#39;Social Networking&#39;, &#39;37&#39;, &#39;1&#39;, &#39;29&#39;, &#39;1&#39;]\n\n\n[&#39;389801252&#39;, &#39;Instagram&#39;, &#39;113954816&#39;, &#39;USD&#39;, &#39;0.0&#39;, &#39;2161558&#39;, &#39;1289&#39;, &#39;4.5&#39;, &#39;4.0&#39;, &#39;10.23&#39;, &#39;12+&#39;, &#39;Photo &amp; Video&#39;, &#39;37&#39;, &#39;0&#39;, &#39;29&#39;, &#39;1&#39;]\n\n\n[&#39;529479190&#39;, &#39;Clash of Clans&#39;, &#39;116476928&#39;, &#39;USD&#39;, &#39;0.0&#39;, &#39;2130805&#39;, &#39;579&#39;, &#39;4.5&#39;, &#39;4.5&#39;, &#39;9.24.12&#39;, &#39;9+&#39;, &#39;Games&#39;, &#39;38&#39;, &#39;5&#39;, &#39;18&#39;, &#39;1&#39;]\n\n\n[&#39;420009108&#39;, &#39;Temple Run&#39;, &#39;65921024&#39;, &#39;USD&#39;, &#39;0.0&#39;, &#39;1724546&#39;, &#39;3842&#39;, &#39;4.5&#39;, &#39;4.0&#39;, &#39;1.6.2&#39;, &#39;9+&#39;, &#39;Games&#39;, &#39;40&#39;, &#39;5&#39;, &#39;1&#39;, &#39;1&#39;]\n\n\nNumber of rows: 7197\nNumber of columns: 16\n"
    }
   ],
   "source": [
    "print(ios_header)\n",
    "print('\\n')\n",
    "explore_data(ios, 0, 4, rows_columns=True)"
   ]
  },
  {
   "source": [
    "The iOS data set includes 7,197 apps with attributes sorted into 16 columns. The columns for the Apple data are in some cases a bit cryptic. Nonetheless, they are easy enough to figure out by looking at the entries. For example, track_name corresponds to the app's name. The most useful seem to be 'track_name', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', and 'prime_genre'. For additional help with the columns, the [documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home) is available."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data Cleaning\n",
    "\n",
    "One of the most critical parts of data analysis is cleaning the data, i.e. removing irrelevant, inaccurate, or duplicate data which would interfere with drawing accurate conclusions.\n",
    "\n",
    "From the [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion) of the Google Play data, we see that row 10,472 is incorrect - it lists the app's rating as 19, while the maximum rating for an app in the Google Play Store should be 5."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;App&#39;, &#39;Category&#39;, &#39;Rating&#39;, &#39;Reviews&#39;, &#39;Size&#39;, &#39;Installs&#39;, &#39;Type&#39;, &#39;Price&#39;, &#39;Content Rating&#39;, &#39;Genres&#39;, &#39;Last Updated&#39;, &#39;Current Ver&#39;, &#39;Android Ver&#39;]\n\n\n[&#39;Life Made WI-Fi Touchscreen Photo Frame&#39;, &#39;1.9&#39;, &#39;19&#39;, &#39;3.0M&#39;, &#39;1,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Everyone&#39;, &#39;&#39;, &#39;February 11, 2018&#39;, &#39;1.0.19&#39;, &#39;4.0 and up&#39;]\n\n\n[&#39;Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook&#39;, &#39;ART_AND_DESIGN&#39;, &#39;4.1&#39;, &#39;159&#39;, &#39;19M&#39;, &#39;10,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Everyone&#39;, &#39;Art &amp; Design&#39;, &#39;January 7, 2018&#39;, &#39;1.0.0&#39;, &#39;4.0.3 and up&#39;]\n"
    }
   ],
   "source": [
    "print(android_header)  # header\n",
    "print('\\n')\n",
    "print(android[10472])  # incorrect row\n",
    "print('\\n')\n",
    "print(android[0])      # example correct row"
   ]
  },
  {
   "source": [
    "According to the discussion, this issue is caused by a missing value for the 'Category' column. To fix this, we'll simply delete the row so it doesn't interfere with the rest of the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del android[10472] # don't run this more than once!"
   ]
  },
  {
   "source": [
    "### Checking for Duplicates\n",
    "\n",
    "Another issue we should check for is duplicate rows. A few duplicate entries can really skew our data and the conclusions we draw from it. Fortunately, we can check the [discussion](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/discussion) around our data; this won't always be an option so we'll also want to check for ourselves.\n",
    "\n",
    "The easiest way to do this is create two lists to account for unique and duplicate app names:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of duplicates:  1181\n\n\n"
    }
   ],
   "source": [
    "android_duplicate_apps = []\n",
    "android_unique_apps = []\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name in android_unique_apps:\n",
    "        android_duplicate_apps.append(name)\n",
    "    else:\n",
    "        android_unique_apps.append(name)\n",
    "\n",
    "print('Number of duplicates: ', len(android_duplicate_apps))\n",
    "print('\\n')"
   ]
  },
  {
   "source": [
    "So there are 1181 cases where an Android app name occurs more than once. Let's check the App Store as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of duplicates:  2\n\n\n[&#39;Mannequin Challenge&#39;, &#39;VR Roller Coaster&#39;]\n"
    }
   ],
   "source": [
    "apple_duplicate_apps = []\n",
    "apple_unique_apps = []\n",
    "\n",
    "for app in ios:\n",
    "    name = app[1] # the iOS data shows the app name in the second column\n",
    "    if name in apple_unique_apps:\n",
    "        apple_duplicate_apps.append(name)\n",
    "    else:\n",
    "        apple_unique_apps.append(name)\n",
    "\n",
    "print('Number of duplicates: ', len(apple_duplicate_apps))\n",
    "print('\\n')\n",
    "print(apple_duplicate_apps)"
   ]
  },
  {
   "source": [
    "It appears there are also two duplicate entries in the App Store data.\n",
    "\n",
    "We could just remove all the duplicate entries, but a better idea would be to examine them a little closer and remove only the entries which make sense to remove. For example, let's take a closer look at the Instagram app entries on Google Play:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;Instagram&#39;, &#39;SOCIAL&#39;, &#39;4.5&#39;, &#39;66577313&#39;, &#39;Varies with device&#39;, &#39;1,000,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Teen&#39;, &#39;Social&#39;, &#39;July 31, 2018&#39;, &#39;Varies with device&#39;, &#39;Varies with device&#39;]\n[&#39;Instagram&#39;, &#39;SOCIAL&#39;, &#39;4.5&#39;, &#39;66577446&#39;, &#39;Varies with device&#39;, &#39;1,000,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Teen&#39;, &#39;Social&#39;, &#39;July 31, 2018&#39;, &#39;Varies with device&#39;, &#39;Varies with device&#39;]\n[&#39;Instagram&#39;, &#39;SOCIAL&#39;, &#39;4.5&#39;, &#39;66577313&#39;, &#39;Varies with device&#39;, &#39;1,000,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Teen&#39;, &#39;Social&#39;, &#39;July 31, 2018&#39;, &#39;Varies with device&#39;, &#39;Varies with device&#39;]\n[&#39;Instagram&#39;, &#39;SOCIAL&#39;, &#39;4.5&#39;, &#39;66509917&#39;, &#39;Varies with device&#39;, &#39;1,000,000,000+&#39;, &#39;Free&#39;, &#39;0&#39;, &#39;Teen&#39;, &#39;Social&#39;, &#39;July 31, 2018&#39;, &#39;Varies with device&#39;, &#39;Varies with device&#39;]\n"
    }
   ],
   "source": [
    "for app in android:\n",
    "    name = app[0]\n",
    "    if name == 'Instagram':\n",
    "        print(app)"
   ]
  },
  {
   "source": [
    "Looking at index 3 (the fourth column), which corresponds to the number of reviews, we see that they are not all the same, which tells us that the data was collected at different times even though it's the same app. With this in mind, it makes sense to only keep the most recent entry - in this case, the one with the highest count of reviews. When we remove all the duplicates, we should be left with 9659:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected length:  9659\n"
    }
   ],
   "source": [
    "print('Expected length: ', len(android) - 1181)"
   ]
  },
  {
   "source": [
    "### Removing Duplicates\n",
    "\n",
    "The safest way to remove the duplicate entries is to confirm the expected number of entries (current total - duplicates), build a new dataset of only unique values, and compare the two before deleting any rows.\n",
    "\n",
    "First, we'll create a dictionary called `reviews_max` (specific to each store), where each dictionary key is a unique app name and the corresponding dictionary value is the highest number of reviews of that app. Then, we'll create a new data set from the dictionary, with just the latest entry per app."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_reviews_max = {}\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if name in android_reviews_max and android_reviews_max[name] < n_reviews:\n",
    "        android_reviews_max[name] = n_reviews\n",
    "        \n",
    "    elif name not in android_reviews_max:\n",
    "        android_reviews_max[name] = n_reviews"
   ]
  },
  {
   "source": [
    "Now let's see if our new data set has the same length as what we expect:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected length: 9659\nActual length: 9659\n"
    }
   ],
   "source": [
    "print('Expected length:', len(android) - 1181)\n",
    "print('Actual length:', len(android_reviews_max))"
   ]
  },
  {
   "source": [
    "Great! Now to do the same for the Apple data. There were only two duplicates, but we'll go through all the steps again anyway."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Expected length: 7195\nActual length: 7195\n"
    }
   ],
   "source": [
    "ios_reviews_max = {}\n",
    "\n",
    "for app in ios:\n",
    "    name = app[1] # the index for the app name in the iOS data is 1.\n",
    "    n_reviews = float(app[5]) # the index for the review count in the iOS data is 5.\n",
    "    \n",
    "    if name in ios_reviews_max and ios_reviews_max[name] < n_reviews:\n",
    "        ios_reviews_max[name] = n_reviews\n",
    "        \n",
    "    elif name not in ios_reviews_max:\n",
    "        ios_reviews_max[name] = n_reviews\n",
    "\n",
    "\n",
    "print('Expected length:', len(ios) - 2)\n",
    "print('Actual length:', len(ios_reviews_max))"
   ]
  },
  {
   "source": [
    "As expected, the lengths match on our iOS data as well. Now we can use our `reviews_max` dictionaries to remove the duplicates. As stated before, we'll only keep the entry with the most reviews for each app.\n",
    "\n",
    "We'll start by creating two empty lists, `clean` and `already_added`. Then we can loop through the data, and add each app to the list only if the number of apps is equal to the value in our `reviews_max` dictionary, and the app doesn't already exist in the list. This will eliminate any duplicates and leave us with just the most up to date row for each unique app."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = []\n",
    "android_already_added = []\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "\n",
    "    if (reviews_max[name] == n_reviews) and (name not in android_already_added):\n",
    "        android_clean.append(app)\n",
    "        android_already_added.append(name)\n",
    "\n",
    "\n",
    "ios_clean = []\n",
    "ios_already_added = []\n",
    "\n",
    "for app in ios:\n",
    "    name = app[1]\n",
    "    n_reviews = float(app[5])\n",
    "\n",
    "    # If we only check the number of reviews, we'll still have some duplicates. Some\n",
    "    # apps have several entries with the max number of reviews.\n",
    "    if (reviews_max[name] == n_reviews) and (name not in ios_already_added):\n",
    "        ios_clean.append(app)\n",
    "        ios_already_added.append(name)"
   ]
  }
 ]
}